{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RoSys - The Robot System","text":"<p>RoSys provides an easy-to-use robot system. Its purpose is similar to ROS. But RoSys is fully based on modern web technologies and focusses on mobile robotics.</p> <p>The full documentation is available at rosys.io.</p>"},{"location":"#principles","title":"Principles","text":""},{"location":"#all-python","title":"All Python","text":"<p>Python is great to write business logic. Computation-heavy tasks are wrapped in processes, accessed through WebSockets or called via C++ bindings. Like you would do in any other Python program.</p>"},{"location":"#modularity","title":"Modularity","text":"<p>You can structure your code as you please. RoSys provides its magic without assuming a specific file structure, configuration files or enforced naming.</p>"},{"location":"#event-loop","title":"Event Loop","text":"<p>Thanks to asyncio you can write your business logic without locks and mutexes. The execution is parallel but not concurrent which makes it easier to read, write and debug. In real-case scenarios this is also much faster than ROS. Its multiprocessing architecture requires too much inter-process communication.</p>"},{"location":"#web-ui","title":"Web UI","text":"<p>Most machines need some kind of human interaction. RoSys is built from the ground up to make sure your robot can be operated fully off the grid with any web browser. This is done by incorporating NiceGUI, a wonderful all-Python UI web framework. It is also possible to proxy the user interface through a gateway for remote operation.</p>"},{"location":"#simulation","title":"Simulation","text":"<p>Robot hardware is often slower than your own computer. To rapidly test out new behavior and algorithms, RoSys provides a simulation mode. Here, all hardware is mocked and can even be manipulated to test wheel blockages and similar.</p>"},{"location":"#testing","title":"Testing","text":"<p>You can use pytest to write high-level integration tests. It is based on the above-described simulation mode and accelerates the robot's time for super fast execution.</p>"},{"location":"#architecture-and-features","title":"Architecture and Features","text":""},{"location":"#modules","title":"Modules","text":"<p>RoSys modules are just Python modules which encapsulate certain functionality. They can hold their own state, register lifecycle hooks, run methods repeatedly and subscribe to or raise events. Modules can depend on other modules which is mostly implemented by passing them into the constructor.</p>"},{"location":"#lifecycle-hooks-and-loops","title":"Lifecycle Hooks and Loops","text":"<p>Modules can register functions via <code>rosys.on_startup</code> or <code>rosys.on_shutdown</code> as well as repeatedly with a given interval with <code>rosys.on_repeat</code>.</p> <p>Note</p> <p>Note that NiceGUI's <code>app</code> object also provides methods <code>app.on_startup</code> and <code>app.on_shutdown</code>, but it is recommended to use RoSys' counterparts: <code>rosys.on_startup</code> ensures the callback is executed after persistent modules have been loaded from storage. If you, e.g., set the <code>rosys.config.simulation_speed</code> programmatically via <code>app.on_startup()</code> instead of <code>rosys.on_startup</code>, the change is overwritten by RoSys' <code>persistence.restore()</code>.</p>"},{"location":"#events","title":"Events","text":"<p>Modules can provide events to allow connecting otherwise separated modules of the system. For example, one module might read sensor data and raise an event <code>NEW_SENSOR_DATA</code>, without knowing of any consumers. Another module can register on <code>NEW_SENSOR_DATA</code> and act accordingly when being called.</p>"},{"location":"#automations","title":"Automations","text":"<p>RoSys provides an <code>Automator</code> module for running \"automations\". Automations are coroutines that can not only be started and stopped, but also paused and resumed, e.g. using <code>AutomationControls</code>. Have a look at our Click-and-drive example.</p>"},{"location":"#persistence","title":"Persistence","text":"<p>Modules can register backup and restore methods to read and write their state to disk.</p>"},{"location":"#time","title":"Time","text":"<p>RoSys uses its own time which is accessible through <code>rosys.time</code>. This way the time can advance much faster in simulation and tests if no CPU-intensive operation is performed. To delay the execution of a coroutine, you should invoke <code>await rosys.sleep(seconds: float)</code>. This creates a delay until the provided amount of RoSys time has elapsed.</p>"},{"location":"#threading-and-multiprocessing","title":"Threading and Multiprocessing","text":"<p>RoSys makes extensive use of async/await to achieve parallelism without threading or multiprocessing. But not every piece of code you want to integrate is offering an asyncio interface. Therefore RoSys provides two handy wrappers:</p> <p>IO-bound: If you need to read from an external device or use a non-async HTTP library like requests, you should wrap the code in a function and await it with <code>await rosys.run.io_bound(...)</code>.</p> <p>CPU-bound: If you need to do some heavy computation and want to spawn another process, you should wrap the code in a function and await it with <code>await rosys.run.cpu_bound(...)</code>.</p>"},{"location":"#safety","title":"Safety","text":"<p>Python (and Linux) is fast enough for most high-level logic, but has no realtime guarantees. Safety-relevant behavior should therefore be put on a suitable microcontroller. It governs the hardware of the robot and must be able to perform safety actions like triggering emergency hold etc.</p> <p>We suggest to use an industrial PC with an integrated controller like the Zauberzeug Robot Brain. It provides a Linux system to run RoSys, offers AI acceleration via NVidia Jetson, two integrated ESP32 microcontrollers and six I/O sockets with up to 24 GPIOs for digital I/Os, CAN, RS485, SPI, I2C, etc. It also has two hardware ENABLE switches and one which is controllable via software.</p> <p>To have flexible configuration for the microcontroller we created another open source project called Lizard. It is a domain-specific language interpreted by the microcontroller which enables you to write reactive hardware behavior without recompiling and flashing.</p>"},{"location":"#user-interface","title":"User Interface","text":"<p>RoSys builds upon the open source project NiceGUI and offers many robot-related UI elements. NiceGUI is a high-level UI framework for the web. This means you can write all UI code in Python and the state is automatically reflected in the browser through WebSockets. See any of our examples.</p> <p>RoSys can also be used with other user interfaces or interaction models if required, for example a completely app-based control through Bluetooth Low Energy with Flutter.</p>"},{"location":"#notifications","title":"Notifications","text":"<p>Modules can notify the user through <code>rosys.notify('message to the user')</code>. When using NiceGUI, the notifications will show as snackbar messages. The history of notifications is stored in the list <code>rosys.notifications</code>.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Thank you for your interest in contributing to RoSys! We are thrilled to have you on board and appreciate your efforts to make this project even better.</p> <p>As a growing open-source project, we understand that it takes a community effort to achieve our goals. That's why we welcome all kinds of contributions, no matter how small or big they are. Whether it's adding new features, fixing bugs, improving documentation, or suggesting new ideas, we believe that every contribution counts and adds value to our project.</p> <p>We have provided a detailed guide on how to contribute to RoSys in our CONTRIBUTING.md file. We encourage you to read it carefully before making any contributions to ensure that your work aligns with the project's goals and standards.</p> <p>If you have any questions or need help with anything, please don't hesitate to reach out to us. We are always here to support and guide you through the contribution process.</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#pushing-code-to-the-robot","title":"Pushing Code to the Robot","text":"<p>To get the code onto the robot you can simply pull your repository. But this requires you to have login credentials on an external machine. And editing files must be done on slow hardware compared to development workstations and laptops. If you use VS Code Remote Development or similar to do actual development on these slow systems, everything feels like jelly. Especially if you run powerful extensions like Pylance.</p> <p>That is why we at Zauberzeug created a small open source tool called LiveSync. It combines a local filesystem watcher with rsync to copy changes to a (slow) remote target whenever your local code changes. This approach has multiple advantages:</p> <ul> <li>work with your personal choice of IDE and tooling</li> <li>run tests (or simulate the production code) locally</li> <li>continuously deploy the development code to the target environment (where auto-reload ensures live preview)</li> <li>almost no overhead on the (slow) target</li> </ul>"},{"location":"development/#logging","title":"Logging","text":"<p>RoSys uses the Python logging package with namespaced loggers. For example, the steerer module writes its logs as <code>rosys.steerer</code>. This can be used for fine-granular control of what should show on the console. As a general starting point we suggest reading the Python Logging HOWTO. In the following examples we use Python's logging <code>dictConfig</code> for configuration, because it provides the most flexibility while having all configuration in one place.</p>"},{"location":"development/#show-info-messages","title":"Show Info Messages","text":"<p>To only print RoSys messages at the info level to the console we can use a configuration like this:</p> <pre><code>#!/usr/bin/env python3\nimport logging\nimport logging.config\n\nfrom nicegui import ui\n\nfrom rosys.driving import Odometer, Steerer, joystick\nfrom rosys.hardware import RobotSimulation, WheelsSimulation\n\nlogging.config.dictConfig({\n    'version': 1,\n    'disable_existing_loggers': True,  # to make sure this config is used\n    'formatters': {\n        'default': {\n            'format': '%(asctime)s - %(levelname)s - %(message)s',\n            'datefmt': '%Y-%m-%d %H:%M:%S',\n        },\n    },\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n            'formatter': 'default',\n            'level': 'DEBUG',\n            'stream': 'ext://sys.stdout'\n        },\n    },\n    'loggers': {\n        '': {  # this root logger is used for everything without a specific logger\n            'handlers': ['console'],\n            'level': 'WARN',\n            'propagate': False,\n        },\n        'rosys': {\n            'handlers': ['console'],\n            'level': 'INFO',\n            'propagate': False,\n        },\n    },\n})\n\nwheels = WheelsSimulation()\nsteerer = Steerer(wheels)\nodometer = Odometer(wheels)\nrobot = RobotSimulation([wheels])\n\njoystick(steerer)\n\nui.run(title='RoSys')\n</code></pre> <p>As you move the joystick, <code>rosys.steerer</code> messages will appear on the console:</p> <pre><code>2022-01-11 06:53:21 - INFO - start steering\n2022-01-11 06:53:22 - INFO - stop steering\n2022-01-11 06:53:23 - INFO - start steering\n2022-01-11 06:53:23 - INFO - stop steering\n</code></pre>"},{"location":"development/#adding-loggers","title":"Adding Loggers","text":"<p>You can easily add more loggers. For example, to see debug messages of the odometer you can add</p> <pre><code>'rosys.odometer': {\n    'handlers': ['console'],\n    'level': 'DEBUG',\n    'propagate': False,\n},\n</code></pre> <p>Most of the time we turn off log propagation to ensure the configuration we defined ourselves is really used.</p>"},{"location":"development/#logging-to-file","title":"Logging to File","text":"<p>Sometimes it is helpful to write intensive logging into a file and only show some messages on the console. For this you can add a file <code>handler</code>:</p> <pre><code>    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n            'formatter': 'default',\n            'level': 'DEBUG',\n            'stream': 'ext://sys.stdout'\n        },\n        'file': {\n            'level': 'DEBUG',\n            'class': 'logging.handlers.RotatingFileHandler',\n            'formatter': 'default',\n            'filename': PATH / 'example.log',\n            'maxBytes': 1024 * 1000,\n            'backupCount': 3\n        }\n    },\n</code></pre> <p>Then you can decide for each logger which handlers should be used:</p> <pre><code>    },\n    'loggers': {\n        '': {  # this root logger is used for everything without a specific logger\n            'handlers': ['console', 'file'],\n            'level': 'WARN',\n            'propagate': False,\n        },\n        'rosys': {\n            'handlers': ['console', 'file'],\n            'level': 'INFO',\n            'propagate': False,\n        },\n        'rosys.event': {\n            'handlers': ['file'],\n            'level': 'DEBUG',\n            'propagate': False,\n        },\n        'rosys.core': {\n            'handlers': ['file'],\n            'level': 'DEBUG',\n            'propagate': False,\n        },\n</code></pre> <p>Note</p> <p>The above file logger writes to <code>~/.rosys</code>. For development it is very helpful to have auto-reloading on file change activated. Therefore logging should always be stored outside of your project's source directory.</p>"},{"location":"development/#formatting","title":"Formatting","text":"<p>It is quite useful to see from which file and line number a log entry was triggered. To keep the log lines from getting too long, you can create a log filter which computes the relative path:</p> <pre><code>class PackagePathFilter(logging.Filter):\n    \"\"\"Provides relative path for log formatter.\n\n    Original code borrowed from https://stackoverflow.com/a/52582536/3419103\n    \"\"\"\n\n    def filter(self, record: logging.LogRecord) -&gt; bool:\n        pathname = record.pathname\n        record.relative_path = None\n        abs_sys_paths = map(cast(Callable[[str], str], os.path.abspath), sys.path)\n        for path in sorted(abs_sys_paths, key=len, reverse=True):  # longer paths first\n            path_ = path if path.endswith(os.sep) else path + os.sep\n            if pathname.startswith(path_):\n                record.relative_path = os.path.relpath(pathname, path_)\n                break\n        return True\n</code></pre> <p>You need to register the filter and apply it in the handler. Then you can change the format for the formatter:</p> <pre><code>    },\n    'filters': {\n        'package_path_filter': {\n            '()': PackagePathFilter,\n        },\n    },\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n            'filters': ['package_path_filter'],\n            'formatter': 'default',\n            'level': 'DEBUG',\n            'stream': 'ext://sys.stdout'\n        },\n    },\n    'loggers': {\n        '': {  # this root logger is used for everything without a specific logger\n            'handlers': ['console'],\n            'level': 'WARN',\n            'propagate': False,\n        },\n        'rosys': {\n            'handlers': ['console'],\n            'level': 'INFO',\n            'propagate': False,\n        },\n</code></pre> <p>Log output then looks like this:</p> <pre><code>2022-01-11 06:51:00.319 [DEBUG] rosys/runtime.py:78: startup completed\n</code></pre>"},{"location":"development/#profiling","title":"Profiling","text":"<p>Note</p> <p>The default RoSys installation via pip does not come with profiling packages. To install them, run</p> <pre><code>python3 -m pip install rosys[profiling]\n</code></pre> <p>Currently this does not work with Python 3.11 because yappy and line-profiler do not support 3.11 yet.</p> <p>You can add a <code>profile</code> decorator to expensive functions and add a profiler button to your UI:</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nimport rosys\nfrom rosys.analysis import profile_button, profiling\n\n\n@profiling.profile\ndef compute() -&gt; None:\n    s = 0\n    for i in range(1_000_000):\n        s += i**2\n    ui.notify(s)\n\n\nrosys.on_repeat(compute, 1.0)\nprofile_button()\n\nui.run()\n</code></pre> <p>When the button is pressed, the profiler yappi will start recording data. When stopped, you will see its output on the console:</p> <pre><code>Line #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     7                                           @profiling.profile\n     8                                           def compute() -&gt; None:\n     9         3         21.0      7.0      0.0      s = 0\n    10   3000003     433138.0      0.1     28.2      for i in range(1_000_000):\n    11   3000000    1098975.0      0.4     71.6          s += i**2\n    12         3       2151.0    717.0      0.1      ui.notify(s)\n</code></pre>"},{"location":"development/#track-async-function-calls","title":"Track async function calls","text":"<p>RoSys provides a <code>@track</code> decorator that you can put above asynchronous functions that are called as part of automations. The UI element <code>track.ui()</code> will show the stack of functions that are currently awaited.</p> <pre><code>#!/usr/bin/env python3\nimport asyncio\n\nfrom nicegui import ui\n\nfrom rosys.analysis import track\n\n\n@track\nasync def do_A():\n    await asyncio.sleep(1)\n\n\n@track\nasync def do_B():\n    await asyncio.sleep(1)\n\n\n@track\nasync def do_something():\n    await asyncio.sleep(1)\n    for _ in range(3):\n        await do_A()\n        await do_B()\n\nui.button('Do something', on_click=do_something)\n\ntrack.ui()\n\nui.run()\n</code></pre>"},{"location":"development/#continuous-build","title":"Continuous Build","text":"<p>We run our continuous integration with GitHub Actions. For each commit mypy and pylint scan the codebase and the pytests are executed.</p>"},{"location":"development/#releases","title":"Releases","text":"<p>We publish releases using tags and milestones on GitHub. In the Release notes we describe our changes. To create a new release perform the following steps:</p> <ol> <li><code>./fetch_milestone.py {0.x.y}</code> with the current milestone name that is to be published.</li> <li>Edit the text the script produces with more details and more mentions of people that participated.</li> <li>In your local repo add a new tag with <code>v0.{x.y}</code> as the name to the current main head.</li> <li>Push to GitHub which starts GitHub Action that performs the following steps:</li> <li>If the pytests are successful, a poetry build and deployment to pypi is issued.</li> <li>A multi-arch Docker image is built and pushed to Docker Hub.</li> <li>Close the milestone on GitHub.</li> <li>Create a new milestone on GitHub with the next version (<code>0.{x.y+1}</code>).</li> <li>Wait for the GitHub Action that was started with your push to finish.</li> <li>Edit the draft of Release notes with the text you created at step 2.</li> </ol>"},{"location":"getting_started/","title":"Getting Started","text":"<p>First install RoSys with pip or Docker. Then create a directory to host your code and put it under version control. Name your entry file <code>main.py</code> and add the following content:</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nimport rosys\n\n# setup\nshape = rosys.geometry.Prism.default_robot_shape()\nrosys.hardware.SerialCommunication.search_paths = ['/dev/ttyUSB0']\nis_real = rosys.hardware.SerialCommunication.is_possible()\nwheels: rosys.hardware.Wheels\nrobot: rosys.hardware.Robot\nif is_real:\n    communication = rosys.hardware.SerialCommunication()\n    robot_brain = rosys.hardware.RobotBrain(communication)\n    can = rosys.hardware.CanHardware(robot_brain)\n    wheels = rosys.hardware.WheelsHardware(robot_brain,\n                                           can=can,\n                                           left_can_address=0x100,\n                                           right_can_address=0x000,\n                                           m_per_tick=0.01571,\n                                           width=0.207,\n                                           is_right_reversed=True)\n    robot = rosys.hardware.RobotHardware([can, wheels], robot_brain)\nelse:\n    wheels = rosys.hardware.WheelsSimulation()\n    robot = rosys.hardware.RobotSimulation([wheels])\nodometer = rosys.driving.Odometer(wheels)\nsteerer = rosys.driving.Steerer(wheels)\n\n# ui\nrosys.driving.keyboard_control(steerer)\nwith ui.scene():\n    rosys.driving.robot_object(shape, odometer)\nui.label('hold SHIFT to steer with the keyboard arrow keys')\nif is_real:\n    ui.button('configure microcontroller', on_click=robot_brain.configure).props('outline')\n\n# start\nui.run(title='RoSys')\n</code></pre> <p>If you launch the program, your browser will open the url http://0.0.0.0:8080/ and present a 3d view:</p> <p></p>"},{"location":"getting_started/#explanation","title":"Explanation","text":""},{"location":"getting_started/#imports","title":"Imports","text":"<p>The user interface is built with NiceGUI. The individual RoSys modules come in packages <code>driving</code>, <code>geometry</code>, <code>hardware</code> and others.</p>"},{"location":"getting_started/#setup","title":"Setup","text":"<p>In this example we create a <code>Steerer</code> which needs an <code>Odometer</code>. Here we work without real hardware, so two wheels are simulated. Please see Hardware for an example which can actually be used on a mobile robot. For visualization purposes we also need the approximate robot shape.</p>"},{"location":"getting_started/#user-interface","title":"User Interface","text":"<p>The user interface consists of keyboard control with access to the steerer as well as a 3D view of the scene. The latter only contains the <code>RobotObject</code> with the given shape. The robot pose is constantly updated from the odometer. See NiceGUI for more details about its API.</p>"},{"location":"getting_started/#start","title":"Start","text":"<p>NiceGUI provides a <code>ui.run</code> command which launches the web server and opens the corresponding web application. If you modify the code, a reload is triggered automatically. This is very convenient, but can be deactivated by passing <code>reload=False</code>.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#on-your-computer","title":"On Your Computer","text":"<pre><code>python3 -m pip install rosys\n</code></pre> <p>See Getting Started for what to do next.</p> <p>Please note that RoSys has been developed for Unix-like systems. While it may partially work on Windows, we do not officially support it.</p>"},{"location":"installation/#on-the-robot","title":"On The Robot","text":"<p>While the above-mentioned installation command works perfectly well in local environments, on a robot it is often easier to run RoSys inside a Docker container. If you already have a <code>main.py</code>, it can be as simple as running</p> <pre><code>docker run -it --rm -v `pwd`:/app zauberzeug/rosys\n</code></pre> <p>from the same directory. See Pushing Code to Robot on how to get your project onto the remote system.</p> <p>More complex Docker setups benefit from a compose file. There are also some specialties needed to start RoSys in different environments (Mac, Linux, NVidia Jetson, ...). To simplify the usage we suggest to use a script called <code>./docker.sh</code> which you can also copy and adapt in your own project. Have a look at the project examples to see how a setup of your own repository may look like.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#asyncio-warning","title":"Asyncio Warning","text":"<p>While running RoSys you may see warnings similar to this one:</p> <pre><code>2021-10-31 15:08:04.040 [WARNING] asyncio: Executing &lt;Task pending name='Task-255' coro=&lt;handle_event() running at /usr/local/lib/python3.9/site-packages/justpy/justpy.py:344&gt; wait_for=&lt;_GatheringFuture pending cb=[&lt;TaskWakeupMethWrapper object at 0x7f7001f8e0&gt;()] created at /usr/local/lib/python3.9/asyncio/tasks.py:705&gt; created at /usr/local/lib/python3.9/site-packages/justpy/justpy.py:261&gt; took 0.238 seconds\n</code></pre> <p>This means some coroutine is clogging the event loop for too long. In the above example it is a whopping 238 ms in which no other actor can do anything. This is an eternity when machine communication is expected to happen about every 10 ms. The warning also provides a (not so readable) hint where the time is consumed.</p> <p>The example above is one of the more frequent scenarios. It means some code inside a user interaction event handler (e.g. <code>handle_event()</code> in <code>justpy.py</code>) is blocking. Try to figure out which UI event code is responsible by commenting out parts of your logic and try to reproduce the warning systematically.</p>"},{"location":"examples/cameras/","title":"Cameras","text":"<p>RoSys provides instant camera access for object detection, remote operation and similar use cases.</p>"},{"location":"examples/cameras/#setup","title":"Setup","text":"<p>USB camera devices are discovered through video4linux (v4l) and accessed with openCV. Therefore the program <code>v4l2ctl</code> and openCV (including python bindings) must be available. We recommend to use the RoSys Docker image which provides the full required software stack. Make sure the container can access the USB devices by starting it with <code>--privileged</code> or explicitly passing the specific <code>--device</code>s.</p>"},{"location":"examples/cameras/#show-captured-images","title":"Show Captured Images","text":"<p>Using <code>rosys.ui</code> you can show the latest captured images from each camera:</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nfrom rosys.vision import SimulatedCamera\n\ncamera = SimulatedCamera(id='test_cam', width=800, height=600)\n\nimage = ui.interactive_image()\nui.timer(0.3, lambda: image.set_source(camera.get_latest_image_url()))\n\nui.run(title='RoSys')\n</code></pre> <p>The <code>ui.timer</code> regularly updates the source property of the <code>ui.image</code>. The cameras <code>latest_image_uri</code> property provides the URI to the latest captured image.</p> <p>This example uses a <code>SimulatedCamera</code> for demonstration. You can directly replace the camera with a <code>UsbCamera</code> or <code>RtspCamera</code> if you know their ids or use their respective providers to discover them automatically.</p>"},{"location":"examples/cameras/#remote-operation","title":"Remote Operation","text":"<p>A fairly often required use case on real mobile robots is the remote operation. In a simple use case you may only need to visualize one camera and have some steering controls. Here we use the <code>NEW_CAMERA</code> event to display the first camera to control real Hardware:</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nimport rosys\n\nif rosys.hardware.SerialCommunication.is_possible():\n    communication = rosys.hardware.SerialCommunication()\n    robot_brain = rosys.hardware.RobotBrain(communication)\n    can = rosys.hardware.CanHardware(robot_brain)\n    wheels = rosys.hardware.WheelsHardware(robot_brain, can=can)\n    robot = rosys.hardware.RobotHardware([can, wheels], robot_brain)\n    camera_provider = rosys.vision.UsbCameraProvider()\nelse:\n    wheels = rosys.hardware.WheelsSimulation()\n    robot = rosys.hardware.RobotSimulation([wheels])\n    rosys.vision.SimulatedCameraProvider.USE_PERSISTENCE = False\n    camera_provider = rosys.vision.SimulatedCameraProvider()\n    camera = rosys.vision.SimulatedCamera(id='test_cam', width=800, height=600)\n    rosys.on_startup(lambda: camera_provider.add_camera(camera))\nsteerer = rosys.driving.Steerer(wheels)\nodometer = rosys.driving.Odometer(wheels)\n\n\nasync def add_main_camera(camera: rosys.vision.Camera) -&gt; None:\n    camera_card.clear()  # remove \"seeking camera\" label\n    with camera_card:\n        main_cam = ui.interactive_image()\n        ui.timer(0.1, lambda: main_cam.set_source(camera.get_latest_image_url()))\n\ncamera_provider.CAMERA_ADDED.register_ui(add_main_camera)\n\nwith ui.card().tight().style('width:30em') as camera_card:\n    ui.label('seeking main camera').classes('m-8 text-center')\n\nwith ui.card().tight().style('width:30em'):\n    with ui.row():\n        with ui.card().tight():\n            rosys.driving.joystick(steerer)\n            rosys.driving.keyboard_control(steerer)\n        ui.markdown('steer with joystick on the left or&lt;br /&gt;SHIFT + arrow keys').classes('m-8 text-center')\n\nui.run(title='RoSys')\n</code></pre> <p>By adding a <code>Joystick</code> and <code>KeyboardControl</code> the robot is ready to go for remote operation.</p>"},{"location":"examples/click-and-drive/","title":"Click-and-drive","text":"<p>In this example we create a simulated robot which uses an automation to drive wherever the user clicks.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\nfrom nicegui.events import SceneClickEventArguments\n\nimport rosys\n\nwheels = rosys.hardware.WheelsSimulation()\nrobot = rosys.hardware.RobotSimulation([wheels])\nodometer = rosys.driving.Odometer(wheels)\ndriver = rosys.driving.Driver(wheels, odometer)\nautomator = rosys.automation.Automator(None, on_interrupt=wheels.stop)\n\n\nasync def handle_click(e: SceneClickEventArguments):\n    for hit in e.hits:\n        if hit.object_id == 'ground':\n            target = rosys.geometry.Point(x=hit.x, y=hit.y)\n            automator.start(driver.drive_to(target))\n\nwith ui.scene(on_click=handle_click):\n    shape = rosys.geometry.Prism.default_robot_shape()\n    rosys.driving.robot_object(shape, odometer, debug=True)\nui.label('click into the scene to drive the robot')\nwith ui.row():\n    rosys.automation.automation_controls(automator)\nui.label('you can also pause/resume or stop the running automation')\n\nui.run(title='RoSys')\n</code></pre> <p></p> Modules Besides wheels, odometer and a robot shape we need a driver that enables the robot to drive along a given path as well as an automator to start and stop such an automated behavior. Click handler NiceGUI's 3D scene allows registering a click handler that can iterate through all hit points and find the target on the ground. Driver Among others, the driver has an async method <code>drive_to</code> which lets the robot follow a straight line to a given target. Automator and automation controls The automator starts the async method and allows pausing, resuming and stopping it, e.g. with the <code>AutomationControls</code> UI element."},{"location":"examples/coordinate_frames/","title":"Coordinate Frames","text":"<p>This example shows how to use <code>Pose3d</code> and <code>Frame3d</code> to represent objects that are connected to each other. Here, we have a moving blue box and a rotating pink box with a camera attached to it. The button allows switching the pink box between the blue box's frame and the world frame at runtime. Note that the relationship between the pink box and the camera is unaffected by the frame switch.</p> <pre><code>#!/usr/bin/env python3\nimport math\n\nfrom nicegui import ui\n\nimport rosys\nfrom rosys.geometry import Pose3d, Rotation\nfrom rosys.vision import CameraSceneObject, SimulatedCalibratableCamera\n\nblue = Pose3d(z=0.5).as_frame('blue')\npink = Pose3d(z=0.75).as_frame('pink').in_frame(blue)\ncamera = SimulatedCalibratableCamera.create_calibrated(id='Camera', z=0.5, roll=math.pi / 2, frame=pink)\n\nwith ui.scene() as scene:\n    blue_box = scene.box(width=1, height=1, depth=1).material(color='SteelBlue')\n    pink_box = scene.box(width=0.5, height=0.5, depth=0.5).material(color='HotPink')\n    camera_object = CameraSceneObject(camera)\n\n\ndef update():\n    blue.x = math.cos(0.5 * rosys.time())\n    blue.y = math.sin(0.5 * rosys.time())\n    pink.rotation *= Rotation.from_euler(0, 0, 0.005)\n\n    blue_box.rotate_R(blue.resolve().rotation.R)\n    blue_box.move(*blue.resolve().translation)\n\n    pink_box.rotate_R(pink.resolve().rotation.R)\n    pink_box.move(*pink.resolve().translation)\n\n    camera_object.rotate_R(camera.calibration.extrinsics.resolve().rotation.R)\n    camera_object.move(*camera.calibration.extrinsics.resolve().translation)\n\n\nrosys.on_repeat(update, interval=0.01)\n\nui.button('Toggle frame', on_click=lambda: pink.in_frame(None if pink.frame_id == 'blue' else blue))\n\nui.run(title='RoSys')\n</code></pre> <p></p>"},{"location":"examples/coordinate_frames/#persistence","title":"Persistence","text":"<p>Frames are defined and accessed through an <code>id</code>. The <code>id</code> must be unique and is used lazily whenever a transformation is needed. This <code>id</code> makes it possible to fully persist <code>Pose3d</code>, <code>Frame3d</code> and their relationships. This can be useful for situation where exact relationships are calibrated at runtime (e.g. multi-camera calibration) or when a robot's axes are expected to be persistent across reboots.</p> <p>For the second case, make sure that you know when the persistence overwrite happens (in the rosys startup handler) so that everything is loaded correctly. See examples/camera_arm for an example on that.</p>"},{"location":"examples/hardware/","title":"Hardware","text":"<p>The other examples use simulated hardware for simplicity and easy execution on any development system. To be able to control real hardware we recommend to derive a <code>Simulation</code> and <code>Hardware</code> version from a shared interface. Depending on your environment you can then instantiate the correct implementation without bothering with it in the rest of your code.</p>"},{"location":"examples/hardware/#custom-implementation","title":"Custom Implementation","text":"<p>For a differential-steering controlled robot, RoSys offers a <code>Wheels</code> base class plus a <code>WheelsSimulation</code>. The following example illustrates how to implement a <code>CustomWheelsHardware</code> module that derives from <code>Wheels</code>, reads the currrent velocity regularly and can be steered with linear and angular velocity.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nimport rosys\n\n\nclass CustomWheelsHardware(rosys.hardware.Wheels):\n\n    def __init__(self) -&gt; None:\n        super().__init__()\n        rosys.on_repeat(self.read_current_velocity, 0.01)\n\n    async def drive(self, linear: float, angular: float) -&gt; None:\n        await super().drive(linear, angular)\n        # TODO send hardware command to drive with given linear and angular velocity\n\n    async def stop(self) -&gt; None:\n        await super().stop()\n        # TODO send hardware command to stop the wheels\n\n    async def read_current_velocity(self) -&gt; None:\n        velocities: list[rosys.geometry.Velocity] = []\n        # TODO: read measured velocities from the hardware\n        self.VELOCITY_MEASURED.emit(velocities)\n\n\ntry:\n    wheels = CustomWheelsHardware()\n    robot = rosys.hardware.Robot([wheels])\nexcept Exception:\n    wheels = rosys.hardware.WheelsSimulation()\n    robot = rosys.hardware.RobotSimulation([wheels])\nodometer = rosys.driving.Odometer(wheels)\nsteerer = rosys.driving.Steerer(wheels)\n\nrosys.driving.keyboard_control(steerer)\nrosys.driving.joystick(steerer)\nui.label().bind_text_from(wheels, 'linear_target_speed', lambda l: f'Linear: {l:.2f} m/s')\nui.label().bind_text_from(wheels, 'angular_target_speed', lambda a: f'Angular: {a:.2f} rad/s')\n\nui.run(title='RoSys')\n</code></pre> <p>Depending on your hardware you may need to modify a PWM signal, send commands via CAN bus or serial, use Protobuf over Ethernet or something else. By raising an exception if the real hardware is not available, a simulated robot is instantiated instead. The robot can be controlled by keyboard or joystick.</p>"},{"location":"examples/hardware/#robot-brain","title":"Robot Brain","text":"<p>The Zauberzeug Robot Brain is an industrial-grade controller which combines artificial intelligence with machinery. It has a built-in ESP32 microcontroller with Lizard installed to do the actual hardware communication in realtime.</p> <p>Serial communication is used to send and receive messages between the built-in NVidia Jetson and the microcontroller. You can call <code>SerialCommunication.is_possible()</code> to automatically switch between simulation and real hardware. The module <code>WheelsHardware</code> expects a <code>RobotBrain</code>, which controls the <code>SerialCommunication</code> with the microcontroller.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nfrom rosys.driving import Odometer, Steerer, joystick, keyboard_control\nfrom rosys.hardware import (\n    CanHardware,\n    RobotBrain,\n    RobotHardware,\n    RobotSimulation,\n    SerialCommunication,\n    WheelsHardware,\n    WheelsSimulation,\n    communication,\n)\n\nis_real = SerialCommunication.is_possible()\nif is_real:\n    communication = SerialCommunication()\n    robot_brain = RobotBrain(communication)\n    can = CanHardware(robot_brain)\n    wheels = WheelsHardware(robot_brain, can=can)\n    robot = RobotHardware([can, wheels], robot_brain)\nelse:\n    wheels = WheelsSimulation()\n    robot = RobotSimulation([wheels])\nodometer = Odometer(wheels)\nsteerer = Steerer(wheels)\n\nkeyboard_control(steerer)\njoystick(steerer)\n\nif is_real:\n    communication.debug_ui()\n    robot_brain.developer_ui()\n\nui.run(title='RoSys')\n</code></pre> <p>With <code>communication.debug_ui()</code> you can add some helpful UI elements for debugging the serial communication. Furthermore, with <code>robot_brain.developer_ui()</code> you can add UI elements to configure and reboot Lizard.</p> <p>The Lizard configuration for a differential-steering controlled robot with an ODrive might look as follows:</p> <pre><code>can = Can(32, 33, 1000000)\n\nl = ODriveMotor(can, 0x000)\nr = ODriveMotor(can, 0x100)\nl.m_per_tick = 0.0627\nr.m_per_tick = 0.0627\n\nwheels = ODriveWheels(l, r)\nwheels.width = 0.515\n\ncore.output(\"core.millis wheels.linear_speed:3 wheels.angular_speed:3\")\n</code></pre>"},{"location":"examples/navigation/","title":"Navigation","text":"<p>This example is similar to Click-and-drive but includes a <code>PathPlanner</code> to find a path around an obstacle.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\nfrom nicegui.events import SceneClickEventArguments\n\nfrom rosys.automation import Automator\nfrom rosys.driving import Driver, Odometer, robot_object\nfrom rosys.geometry import Point, Pose, Prism\nfrom rosys.hardware import RobotSimulation, WheelsSimulation\nfrom rosys.pathplanning import Obstacle, PathPlanner, obstacle_object, path_object\n\nshape = Prism.default_robot_shape()\nPathPlanner.USE_PERSISTENCE = False\npath_planner = PathPlanner(shape)\npath_planner.obstacles['0'] = Obstacle(id='0', outline=[Point(x=3, y=0), Point(x=0, y=3), Point(x=3, y=3)])\nwheels = WheelsSimulation()\nrobot = RobotSimulation([wheels])\nodometer = Odometer(wheels)\ndriver = Driver(wheels, odometer)\nautomator = Automator(None, on_interrupt=wheels.stop)\n\n\nasync def handle_click(e: SceneClickEventArguments):\n    for hit in e.hits:\n        if hit.object_id == 'ground':\n            goal = Pose(x=hit.x, y=hit.y, yaw=odometer.prediction.direction(Point(x=hit.x, y=hit.y)))\n            path = await path_planner.search(start=odometer.prediction, goal=goal)\n            path3d.update(path)\n            automator.start(driver.drive_path(path))\n\nwith ui.scene(on_click=handle_click, width=600):\n    robot_object(shape, odometer)\n    obstacle_object(path_planner)\n    path3d = path_object()\n\nui.label('click into the scene to drive the robot')\n\nui.run(title='RoSys')\n</code></pre>"},{"location":"examples/navigation/#path-following","title":"Path Following","text":"<p>When following a path, a \"carrot\" is dragged along a spline and the robot follows it like a donkey. Additionally, there is a virtual \"hook\" attached to the robot, which is pulled towards the carrot.</p> <p>There are three parameters:</p> <ul> <li><code>hook_offset</code>: How far from the wheel axis (i.e. the coordinate center of the robot) is the hook, which is pulled towards the carrot.</li> <li><code>carrot_offset</code>: How far ahead of the carrot is the robot pulled. This parameter is necessary in order to have the hook pulled a bit further, even though the carrot already reached the end of the spline.</li> <li><code>carrot_distance</code>: How long is the \"thread\" between hook and carrot (or the offset point ahead of the carrot, respectively).</li> </ul> <p>In the following illustration these points are depicted as spheres: the coordinate center of the robot (blue, small), the hook (blue, large), carrot (orange, small), offset point ahead of the carrot (orange, large).</p> <p></p> <p>You can display a wire frame version of the robot by passing <code>debug=true</code> to the <code>robot_object</code>.</p> <p>Note</p> <p>The automation <code>drive_spline</code> has an optional argument <code>flip_hook</code>. It turns the hook 180 degrees to the back of the robot, while preserving the distance <code>hook_offset</code> to the robot's coordinate center. This allows the robot to drive backwards to a point behind it instead of turning around and approaching it forwards.</p> <p>A more complex example can be found in the RoSys GitHub repository. There you can create new obstacles and choose between straight driving or navigation.</p>"},{"location":"examples/persistence/","title":"Persistence","text":"<p>RoSys' <code>PersistentModule</code> provides an easy interface to backup and restore parts of the object state. The following example demonstrates a <code>Model</code> class that has <code>value</code>, which is manipulated with a <code>ui.slider</code>.</p> <pre><code>#!/usr/bin/env python3\nfrom typing import Any\n\nfrom nicegui import ui\n\nfrom rosys import persistence\n\n\nclass Model(persistence.PersistentModule):\n\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.value: float = 1.0\n\n    def restore(self, data: dict[str, Any]) -&gt; None:\n        self.value = data.get('value', 1.0)\n\n    def backup(self) -&gt; dict[str, Any]:\n        return {\n            'value': self.value,\n        }\n\n\nmodel = Model()\nui.slider(min=0, max=10.0, step=0.1).bind_value(model, 'value').props('label-always')\n\nui.run(title='RoSys')\n</code></pre> <p>By deriving from <code>PersistentModule</code> and implementing <code>backup</code> and <code>restore</code>, RoSys will automatically write the value to a file in the directory ~/.rosys/. The filename contains the name of the module. After restarting the script, the value will be restored to its last state.</p> <p>The <code>request_backup</code> method can be called to enforce a backup within RoSys' next backup cycle, which happens every 10 seconds. During shutdown, all backups are performed, independent of whether <code>request_backup</code> has been called.</p> <p>The <code>backup</code> function can return any JSON-serializable dictionary that represents the current state. It should match the <code>restore</code> function so that it can translate it back to object state.</p> <p>You should choose wisely which values to persist. Try to avoid consuming unnecessary CPU and IO bandwidth for volatile things like wheel odometry or other sensor readings.</p> <p>Note that the persistence module contains a number of helper functions:</p> <ul> <li><code>to_dict</code>: converts (dictionaries or lists of) dataclasses into a dictionary (or list)</li> <li><code>from_dict</code>: converts a dictionary into a dataclass of given type</li> <li><code>replace_dict</code>: replaces the content of a dictionary using <code>from_dict</code> for each item</li> <li><code>replace_list</code>: replaces the content of a list using <code>from_dict</code> for each item</li> <li><code>replace_set</code>: replaces the content of a set using <code>from_dict</code> for each item</li> <li><code>replace_dataclass</code>: replaces the attributes of a dataclass with the values of a dictionary</li> </ul> <p>The persistence module also provides UI buttons for exporting the contents of the ~/.rosys directory to a single file and for importing such a file.</p> <p>If you want to automatically keep daily backups, you can use the <code>BackupSchedule</code> module. It will backup all the contents of your ~/.rosys directory at a configurable directory and at a given time each day. When a maximum number of backup files is reached (specified with <code>backup_count</code>), it will delete the oldest file.</p>"},{"location":"examples/play-pause-stop/","title":"Play-pause-stop","text":"<p>In this example, we use the <code>AutomationControls</code> UI element to start, pause and stop an automation. Here we let the robot drive to predefined checkpoints one after the other.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nimport rosys\nfrom rosys.geometry import Point\n\n\nasync def run() -&gt; None:\n    for c in checkpoints:\n        await driver.drive_to(c)\n\ncheckpoints: list[Point] = [Point(x=-3, y=1), Point(x=3, y=3), Point(x=2, y=-2)]\nwheels = rosys.hardware.WheelsSimulation()\nrobot = rosys.hardware.RobotSimulation([wheels])\nodometer = rosys.driving.Odometer(wheels)\ndriver = rosys.driving.Driver(wheels, odometer)\nautomator = rosys.automation.Automator(None, default_automation=run, on_interrupt=wheels.stop)\n\nwith ui.scene(width=600).classes('drop-shadow-lg') as scene:\n    rosys.driving.robot_object(rosys.geometry.Prism.default_robot_shape(), odometer)\n    for i, point in enumerate(checkpoints):\n        scene.text(f'{i+1}').move(x=point.x, y=point.y)\n\nwith ui.row():\n    rosys.automation.automation_controls(automator)\n\nui.run(title='RoSys')\n</code></pre> <p>To achieve this, we define our automation as an async method and pass it to the <code>default_automation</code> parameter of the <code>Automator</code>.</p> <p></p>"},{"location":"examples/schedule/","title":"Schedule automations","text":"<p>You can schedule when the robot should be active. The <code>Schedule</code> module comes with its own UI to manipulate the half-hourly time plan.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nfrom rosys.automation import Automator, Schedule, automation_controls\nfrom rosys.driving import Driver, Odometer, robot_object\nfrom rosys.geometry import Point, Prism\nfrom rosys.hardware import RobotSimulation, WheelsSimulation\n\n\nasync def drive_around() -&gt; None:\n    while True:\n        await driver.drive_to(Point(x=1, y=0))\n        await driver.drive_to(Point(x=0, y=0))\n\n\nasync def drive_home() -&gt; None:\n    await driver.drive_to(Point(x=-3, y=0))\n\n\nshape = Prism.default_robot_shape()\nwheels = WheelsSimulation()\nrobot = RobotSimulation([wheels])\nodometer = Odometer(wheels)\ndriver = Driver(wheels, odometer)\nautomator = Automator(None, default_automation=drive_around, on_interrupt=wheels.stop)\n\nlocations = {\n    (52.520008, 13.404954): 'Berlin',\n    (40.730610, -73.935242): 'New York',\n    None: 'no location',\n}\nschedule = Schedule(automator=automator, on_activate=drive_around, on_deactivate=drive_home,\n                    location=None, locations=locations, is_enabled=True)\nschedule.fill(False)  # disable at all times so the user can enable it manually\nschedule.is_enabled = True  # the schedule must be enabled to take any effect\n\nwith ui.row().classes('items-end'):\n    schedule.ui()\n    with ui.column().classes('items-end'):\n        with ui.row():\n            automation_controls(automator)\n        with ui.scene(height=360):\n            robot_object(shape, odometer)\n\nui.run(title='RoSys')\n</code></pre> <p>There is also the possibility to pass a geographic location to restrict the activity to daylight only.</p>"},{"location":"examples/simulation_speed/","title":"Simulation Speed","text":"<p>When running in simulation you can accelerate the time. Here we have set up a fence in which the robot moves to random positions. With a simple slider the execution time is accelerated. Note how the time advances faster if the simulation speed is increased. The driving speed of the robot remains the same.</p> <p></p> <p>This is achieved simply by placing <code>rosys.simulation_ui()</code> in your UI. The rest of the code is needed to define the boundary, draw it in the 3D scene and start the automation for random movement:</p> <pre><code>#!/usr/bin/env python3\nimport random\n\nfrom nicegui import ui\n\nimport rosys\nfrom rosys.automation import Automator\nfrom rosys.driving import Driver, Odometer, robot_object\nfrom rosys.geometry import Point, Prism\nfrom rosys.hardware import RobotSimulation, WheelsSimulation\n\nwheels = WheelsSimulation()\nrobot = RobotSimulation([wheels])\nodometer = Odometer(wheels)\ndriver = Driver(wheels, odometer)\ndriver.parameters.linear_speed_limit = 3\ndriver.parameters.angular_speed_limit = 1\nautomator = Automator(None, on_interrupt=wheels.stop)\n\nsize = 3\nboundary = [(-size, -size), (-size, size), (size, size), (size, -size)]\n\nwith ui.scene() as scene:\n    robot_object(Prism.default_robot_shape(), odometer)\n    for i, a in enumerate(boundary):\n        b = boundary[(i+1) % len(boundary)]\n        ui.scene.line([*a, 0.1], [*b, 0.1]).material('red')\n    scene.move_camera(0, 0, 8)\nwith ui.column().style('width: 400px'):\n    rosys.simulation_ui()\n\n\nasync def move_around():\n    while True:\n        await driver.drive_to(Point(x=random.uniform(-size, size), y=random.uniform(-size, size)))\n\nrosys.on_startup(lambda: automator.start(move_around()))\n\nui.run(title='RoSys')\n</code></pre>"},{"location":"examples/steering/","title":"Steering","text":"<p>The following example simulates a robot that can be steered using keyboard controls or a joystick via web interface.</p> <pre><code>#!/usr/bin/env python3\nfrom nicegui import ui\n\nfrom rosys.driving import Odometer, Steerer, joystick, keyboard_control, robot_object\nfrom rosys.geometry import Prism\nfrom rosys.hardware import RobotSimulation, WheelsSimulation\n\nshape = Prism.default_robot_shape()\nwheels = WheelsSimulation()\nrobot = RobotSimulation([wheels])\nodometer = Odometer(wheels)\nsteerer = Steerer(wheels)\n\nkeyboard_control(steerer)\njoystick(steerer, size=50, color='blue')\nwith ui.scene():\n    robot_object(shape, odometer)\n\nui.run(title='RoSys')\n</code></pre> <p></p> Keyboard Control By adding a <code>KeyboardControl</code> to the user interface you enable steering the robot with the keyboard. Press the arrow keys while holding the SHIFT key to steer the robot. You can also modify the speed of the robot by pressing the a number key. Use the optional parameter <code>default_speed</code> to change the initial value. Joystick When operating from a mobile phone, you can use a <code>Joystick</code> to create a UI element with touch control. You can drive the robot by dragging the mouse inside the top left square."},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>analysis</li> <li>automation</li> <li>driving</li> <li>hardware</li> <li>helpers</li> <li>pathplanning</li> <li>system</li> <li>vision<ul> <li>camera</li> <li>rtsp_camera</li> <li>simulated_camera</li> <li>usb_camera</li> </ul> </li> </ul>"},{"location":"reference/rosys/analysis/","title":"analysis","text":""},{"location":"reference/rosys/analysis/#rosys.analysis.logging_page","title":"logging_page","text":""},{"location":"reference/rosys/analysis/#rosys.analysis.logging_page.LoggingPage","title":"LoggingPage","text":"<pre><code>LoggingPage(group_names: list[str] | None = None)\n</code></pre> <p>Logging Page</p> <p>This module creates a page to change the log levels of different loggers. A list of logger names like <code>[\"field_friend\", \"rosys\"]</code> can be passed to group them together. It is mounted at /logging.</p>"},{"location":"reference/rosys/analysis/#rosys.analysis.profile_button","title":"profile_button","text":"<pre><code>profile_button()\n</code></pre> <p>               Bases: <code>button</code></p> <p>The profile button allows starting and stopping a profiling session.</p> <p>Use the <code>profiling.profile</code> decorator for including functions or methods in the analysis. The results are shown on the console.</p>"},{"location":"reference/rosys/automation/","title":"automation","text":""},{"location":"reference/rosys/automation/#rosys.automation.Automator","title":"Automator","text":"<pre><code>Automator(\n    steerer: Steerer | None,\n    *,\n    default_automation: Callable | None = None,\n    on_interrupt: Callable | None = None\n)\n</code></pre> <p>An automator allows running automations, i.e. coroutines that can be paused and resumed.</p> <p>See Click-and-drive for a simple example of an automation.</p> <p>steerer: If provided, manually steering the robot will pause a currently running automation.</p> <p>default_automation: If provided, it allows the automator to start a new automation without passing an automation (e.g. via an \"Play\"-button like offered by the automation controls). The passed function should return a new coroutine on every call (see Play-pause-stop example).</p> <p>on_interrupt: Optional callback that will be called when an automation pauses or stops (the cause is provided as string parameter).</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.disable","title":"disable","text":"<pre><code>disable(because: str) -&gt; None\n</code></pre> <p>Disables the automator.</p> <p>No automations can be started while the automator is disabled. If an automation is running or paused it will be stopped. You need to provide a cause which will be used as notification message.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.enable","title":"enable","text":"<pre><code>enable() -&gt; None\n</code></pre> <p>Enables the automator.</p> <p>It is enabled by default. It can be disabled by calling <code>disable()</code>.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.pause","title":"pause","text":"<pre><code>pause(because: str) -&gt; None\n</code></pre> <p>Pauses the current automation.</p> <p>You need to provide a cause which will be used as notification message.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.resume","title":"resume","text":"<pre><code>resume() -&gt; None\n</code></pre> <p>Resumes the current automation.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.set_default_automation","title":"set_default_automation","text":"<pre><code>set_default_automation(\n    default_automation: Callable | None,\n) -&gt; None\n</code></pre> <p>Sets the default automation.</p> <p>You can pass a function that returns a new coroutine on every call.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.start","title":"start","text":"<pre><code>start(\n    coro: Coroutine | None = None, *, paused: bool = False\n) -&gt; None\n</code></pre> <p>Starts a new automation.</p> <p>You can pass any coroutine. The automator will make sure it can be paused, resumed and stopped.</p>"},{"location":"reference/rosys/automation/#rosys.automation.Automator.stop","title":"stop","text":"<pre><code>stop(because: str) -&gt; None\n</code></pre> <p>Stops the current automation.</p> <p>You need to provide a cause which will be used as notification message.</p>"},{"location":"reference/rosys/automation/#events","title":"Events","text":"Name Description AUTOMATION_STARTED an automation has been started AUTOMATION_PAUSED an automation has been paused (string argument: description of the cause) AUTOMATION_RESUMED an automation has been resumed AUTOMATION_STOPPED an automation has been stopped (string argument: description of the cause) AUTOMATION_FAILED an automation has failed to complete (string argument: description of the cause) AUTOMATION_COMPLETED an automation has been completed"},{"location":"reference/rosys/automation/#rosys.automation.app_controls","title":"app_controls","text":"<pre><code>app_controls(robot_brain: RobotBrain, automator: Automator)\n</code></pre> <p>The AppControls module enables the connection with a mobile-app-based user interface.</p> <p>It uses a given RobotBrain object to communicate with Lizard running on a microcontroller and in turn being connected to a mobile app via Bluetooth Low Energy. It displays buttons to control a given automator.</p>"},{"location":"reference/rosys/automation/#rosys.automation.app_controls.notify","title":"notify  <code>async</code>","text":"<pre><code>notify(msg: str) -&gt; None\n</code></pre> <p>show notification as Snackbar message on mobile device</p>"},{"location":"reference/rosys/automation/#rosys.automation.app_controls.set_info","title":"set_info  <code>async</code>","text":"<pre><code>set_info(msg: str) -&gt; None\n</code></pre> <p>replace constantly shown info text on mobile device</p>"},{"location":"reference/rosys/automation/#events_1","title":"Events","text":"Name Description APP_CONNECTED an app connected via bluetooth (used to refresh information or similar)"},{"location":"reference/rosys/automation/#rosys.automation.automation_controls","title":"automation_controls","text":"<pre><code>automation_controls(automator: Automator)\n</code></pre> <p>This UI element contains start/stop/pause/resume buttons for controlling a given automator.</p> <p>See Play-pause-stop for a simple example of the automation controls.</p>"},{"location":"reference/rosys/automation/#rosys.automation.parallelize","title":"parallelize","text":""},{"location":"reference/rosys/automation/#rosys.automation.parallelize.parallelize","title":"parallelize","text":"<pre><code>parallelize(\n    *coros: Coroutine,\n    return_when_first_completed: bool = False\n)\n</code></pre> <p>Parallelize multiple coroutines.</p> <p>This class allows to combine multiple coroutines into one that can be passed to the <code>automator &lt;https://rosys.io/reference/rosys/automation/#rosys.automation.Automator&gt;</code>__ to run them in parallel.</p>"},{"location":"reference/rosys/driving/","title":"driving","text":""},{"location":"reference/rosys/driving/#rosys.driving.Driver","title":"Driver","text":"<pre><code>Driver(wheels: Drivable, odometer: Odometer | PoseProvider)\n</code></pre> <p>The driver module allows following a given path.</p> <p>It requires a wheels module (or any drivable hardware representation) to execute individual drive commands. It also requires an odometer to get a current prediction of the robot's pose. Its <code>parameters</code> allow controlling the specific drive behavior.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.prediction","title":"prediction  <code>property</code>","text":"<pre><code>prediction: Pose\n</code></pre> <p>The current prediction of the robot's pose based on the odometer.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.abort","title":"abort","text":"<pre><code>abort() -&gt; None\n</code></pre> <p>Abort the current drive routine.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.drive_circle","title":"drive_circle  <code>async</code>","text":"<pre><code>drive_circle(\n    target: Point,\n    *,\n    angle_threshold: float = np.deg2rad(5),\n    backward: bool = False,\n    stop_at_end: bool = True\n) -&gt; None\n</code></pre> <p>Drive in a circular path.</p> <p>When the angle between the robot's current direction and the target direction is less than <code>angle_threshold</code>, the robot stops driving.</p> <p>:param target: The target point to drive towards. :param angle_threshold: The angle threshold to stop driving (radians, default: 5\u00b0). :param backward: Whether to drive backwards (default: <code>False</code>). :param stop_at_end: Whether to stop the robot at the end of the circular path (default: <code>False</code>). :raises: DrivingAbortedException: If the driving process is aborted.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.drive_path","title":"drive_path  <code>async</code>","text":"<pre><code>drive_path(\n    path: list[PathSegment],\n    *,\n    throttle_at_end: bool = True,\n    stop_at_end: bool = True\n) -&gt; None\n</code></pre> <p>Drive along a given path.</p> <p>:param path: The path to drive along, composed of PathSegments. :param throttle_at_end: Whether to throttle down when approaching the end of the path (default: <code>True</code>). :param stop_at_end: Whether to stop at the end of the path (default: <code>True</code>). :raises: DrivingAbortedException: If the driving process is aborted.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.drive_spline","title":"drive_spline  <code>async</code>","text":"<pre><code>drive_spline(\n    spline: Spline,\n    *,\n    flip_hook: bool = False,\n    throttle_at_end: bool = True,\n    stop_at_end: bool = True\n) -&gt; None\n</code></pre> <p>Drive along a given spline.</p> <p>:param spline: The spline to drive along. :param flip_hook: Whether to flip the hook offset (default: <code>False</code>). :param throttle_at_end: Whether to throttle down when approaching the end of the spline (default: <code>True</code>). :param stop_at_end: Whether to stop at the end of the spline (default: <code>True</code>). :raises DrivingAbortedException: If the driving process is aborted.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Driver.drive_to","title":"drive_to  <code>async</code>","text":"<pre><code>drive_to(\n    target: Point,\n    *,\n    backward: bool = False,\n    throttle_at_end: bool = True,\n    stop_at_end: bool = True\n) -&gt; None\n</code></pre> <p>Drive to a given target point.</p> <p>:param target: The target point to drive to. :param backward: Whether to drive backwards (default: <code>False</code>). :param throttle_at_end: Whether to throttle down when approaching the target point (default: <code>True</code>). :param stop_at_end: Whether to stop at the target point (default: <code>True</code>). :raises: DrivingAbortedException: If the driving process is aborted.</p>"},{"location":"reference/rosys/driving/#rosys.driving.Odometer","title":"Odometer","text":"<pre><code>Odometer(wheels: VelocityProvider)\n</code></pre> <p>An odometer collects velocity information from a given wheels module (or any velocity-providing hardware representation).</p> <p>It can also handle \"detections\", i.e. absolute pose information with timestamps. Given the history of previously received velocities, it can update its prediction of the current pose.</p> <p>The <code>get_pose</code> method provides robot poses from the within the last 10 seconds.</p>"},{"location":"reference/rosys/driving/#events","title":"Events","text":"Name Description WHEELS_TURNED the wheels have turned with non-zero velocity PREDICTION_UPDATED the pose prediction has been updated"},{"location":"reference/rosys/driving/#rosys.driving.Steerer","title":"Steerer","text":"<pre><code>Steerer(wheels: Drivable, speed_scaling: float = 1.0)\n</code></pre> <p>The steerer module translates x-y information (e.g. from a joystick) to linear/angular velocities sent to the robot.</p> <p>The wheels module can be any drivable hardware representation. Changing the steering state emits events that can be used to react to manual user interaction.</p>"},{"location":"reference/rosys/driving/#events_1","title":"Events","text":"Name Description STEERING_STARTED steering has started STEERING_STOPPED steering has stopped"},{"location":"reference/rosys/driving/#rosys.driving.driver_object","title":"driver_object","text":""},{"location":"reference/rosys/driving/#rosys.driving.driver_object.DriverObject","title":"DriverObject","text":"<pre><code>DriverObject(driver: Driver)\n</code></pre> <p>               Bases: <code>Group</code></p> <p>The DriverObject UI element displays the path following process in a 3D scene.</p> <p>The current pose is taken from a given odometer. An optional driver module shows debugging information about a current path-following process. The <code>debug</code> argument can be set to show a wireframe instead of a closed polygon.</p>"},{"location":"reference/rosys/driving/#rosys.driving.joystick","title":"joystick","text":"<pre><code>joystick(steerer: Steerer, **options)\n</code></pre> <p>               Bases: <code>joystick</code></p> <p>The Joystick UI element allows controlling a given steerer via touch events.</p>"},{"location":"reference/rosys/driving/#rosys.driving.keyboard_control","title":"keyboard_control","text":"<pre><code>keyboard_control(\n    steerer: Steerer,\n    *,\n    default_speed: float = 2.0,\n    connection_timeout: float = 1.0,\n    check_connection_interval: float = 1.0\n)\n</code></pre> <p>The KeyboardControl UI element allows controlling a given steerer via keyboard events.</p> <p>Hold shift while pressing an arrow key to steer the robot. You can change the speed with the number keys 1 to 9 and the initial speed via the <code>default_speed</code> argument.</p>"},{"location":"reference/rosys/driving/#events_2","title":"Events","text":"Name Description CONNECTION_INTERRUPTED the keyboard control has lost connection to the browser."},{"location":"reference/rosys/driving/#rosys.driving.robot_object","title":"robot_object","text":"<pre><code>robot_object(\n    shape: Prism, odometer: Odometer, *, debug: bool = False\n)\n</code></pre> <p>               Bases: <code>Group</code></p> <p>The RobotObject UI element displays the robot with its given shape in a 3D scene.</p> <p>The current pose is taken from a given odometer. The <code>debug</code> argument can be set to show a wireframe instead of a closed polygon.</p>"},{"location":"reference/rosys/driving/#rosys.driving.robot_object.with_stl","title":"with_stl","text":"<pre><code>with_stl(\n    url: str,\n    *,\n    x: float = 0,\n    y: float = 0,\n    z: float = 0,\n    omega: float = 0,\n    phi: float = 0,\n    kappa: float = 0,\n    scale: float = 1.0,\n    color: str = \"#ffffff\",\n    opacity: float = 1.0\n) -&gt; RobotObject\n</code></pre> <p>Sets an STL to be displayed as the robot.</p> <p>The file can be served from a local directory with app.add_static_files(url, path).</p>"},{"location":"reference/rosys/hardware/","title":"hardware","text":""},{"location":"reference/rosys/hardware/#rosys.hardware.Bms","title":"Bms","text":"<pre><code>Bms(**kwargs)\n</code></pre> <p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>The BMS module communicates with a simple battery management system over a serial connection.</p> <p>The BMS module provides measured voltages as an event.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Bms.is_above_percent","title":"is_above_percent","text":"<pre><code>is_above_percent(value: float) -&gt; bool\n</code></pre> <p>Returns whether the battery is charged above the given percentage.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Bms.is_above_voltage","title":"is_above_voltage","text":"<pre><code>is_above_voltage(value: float) -&gt; bool\n</code></pre> <p>Returns whether the battery voltage is above the given value.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Bms.is_below_percent","title":"is_below_percent","text":"<pre><code>is_below_percent(value: float) -&gt; bool\n</code></pre> <p>Returns whether the battery is charged below the given percentage.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Bms.is_below_voltage","title":"is_below_voltage","text":"<pre><code>is_below_voltage(value: float) -&gt; bool\n</code></pre> <p>Returns whether the battery voltage is below the given value.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.BmsHardware","title":"BmsHardware","text":"<pre><code>BmsHardware(\n    robot_brain: RobotBrain,\n    *,\n    expander: ExpanderHardware | None = None,\n    name: str = \"bms\",\n    rx_pin: int = 26,\n    tx_pin: int = 27,\n    baud: int = 9600,\n    num: int = 1,\n    charge_detect_threshold: float = -0.4\n)\n</code></pre> <p>               Bases: <code>Bms</code>, <code>ModuleHardware</code></p> <p>This module implements the hardware interface for the BMS module.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.BmsSimulation","title":"BmsSimulation","text":"<pre><code>BmsSimulation(\n    is_charging: Callable[[], bool] | None = None,\n    fixed_voltage: float | None = None,\n)\n</code></pre> <p>               Bases: <code>Bms</code>, <code>ModuleSimulation</code></p> <p>This module simulates a BMS module.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Bumper","title":"Bumper","text":"<pre><code>Bumper(estop: EStop | None, **kwargs)\n</code></pre> <p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>A module that detects when a bumper is triggered.</p>"},{"location":"reference/rosys/hardware/#events","title":"Events","text":"Name Description BUMPER_TRIGGERED a bumper was triggered (argument: the bumper name)"},{"location":"reference/rosys/hardware/#rosys.hardware.BumperHardware","title":"BumperHardware","text":"<pre><code>BumperHardware(\n    robot_brain: RobotBrain,\n    *,\n    expander: ExpanderHardware | None = None,\n    name: str = \"bumper\",\n    pins: dict[str, int],\n    estop: EStop | None = None\n)\n</code></pre> <p>               Bases: <code>Bumper</code>, <code>ModuleHardware</code></p> <p>Hardware implementation of the bumper module.</p> <p>The module expects a dictionary of pin names and pin numbers. If an e-stop is provided, the module will not trigger bumpers if the e-stop is active.</p>"},{"location":"reference/rosys/hardware/#events_1","title":"Events","text":"Name Description BUMPER_TRIGGERED a bumper was triggered (argument: the bumper name)"},{"location":"reference/rosys/hardware/#rosys.hardware.BumperSimulation","title":"BumperSimulation","text":"<pre><code>BumperSimulation(estop: EStop | None, **kwargs)\n</code></pre> <p>               Bases: <code>Bumper</code>, <code>ModuleSimulation</code></p> <p>Simulation of the bumper module.</p>"},{"location":"reference/rosys/hardware/#events_2","title":"Events","text":"Name Description BUMPER_TRIGGERED a bumper was triggered (argument: the bumper name)"},{"location":"reference/rosys/hardware/#rosys.hardware.Communication","title":"Communication","text":"<pre><code>Communication()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>This abstract module defines an interface for communicating with a microcontroller.</p> <p>Besides sending and receiving messages a communication module provides a property whether communication is possible. It can also provide a piece of debug UI.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.EStop","title":"EStop","text":"<pre><code>EStop(**kwargs)\n</code></pre> <p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>A module that detects when the e-stop is triggered.</p> <p>The module has a boolean field <code>active</code> that is true when the e-stop is triggered.</p> <p>There is also a boolean field <code>is_soft_estop_active</code> that is true when the soft e-stop is active. It can be set to true or false by calling <code>set_soft_estop(active: bool)</code>.</p>"},{"location":"reference/rosys/hardware/#events_3","title":"Events","text":"Name Description ESTOP_TRIGGERED the e-stop was triggered"},{"location":"reference/rosys/hardware/#rosys.hardware.EStopHardware","title":"EStopHardware","text":"<pre><code>EStopHardware(\n    robot_brain: RobotBrain,\n    *,\n    name: str = \"estop\",\n    pins: dict[str, int]\n)\n</code></pre> <p>               Bases: <code>EStop</code>, <code>ModuleHardware</code></p> <p>Hardware implementation of the e-stop module.</p> <p>The module expects a dictionary of pin names and pin numbers.</p>"},{"location":"reference/rosys/hardware/#events_4","title":"Events","text":"Name Description ESTOP_TRIGGERED the e-stop was triggered"},{"location":"reference/rosys/hardware/#rosys.hardware.EStopSimulation","title":"EStopSimulation","text":"<pre><code>EStopSimulation(**kwargs)\n</code></pre> <p>               Bases: <code>EStop</code>, <code>ModuleSimulation</code></p> <p>Simulation of the e-stop module.</p>"},{"location":"reference/rosys/hardware/#events_5","title":"Events","text":"Name Description ESTOP_TRIGGERED the e-stop was triggered"},{"location":"reference/rosys/hardware/#rosys.hardware.ExpanderHardware","title":"ExpanderHardware","text":"<pre><code>ExpanderHardware(\n    robot_brain: RobotBrain,\n    *,\n    name: str = \"p0\",\n    serial: SerialHardware,\n    boot: int = 25,\n    enable: int = 14\n)\n</code></pre> <p>               Bases: <code>ModuleHardware</code></p> <p>The expander module represents a second ESP microcontroller connected to the core ESP via serial.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Gnss","title":"Gnss","text":"<pre><code>Gnss()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>A GNSS module that provides measurements from a GNSS receiver.</p>"},{"location":"reference/rosys/hardware/#events_6","title":"Events","text":"Name Description NEW_MEASUREMENT a new measurement has been received (argument: <code>GnssMeasurement</code>)"},{"location":"reference/rosys/hardware/#rosys.hardware.GnssHardware","title":"GnssHardware","text":"<pre><code>GnssHardware(*, antenna_pose: Pose | None)\n</code></pre> <p>               Bases: <code>Gnss</code></p> <p>This hardware module connects to a Septentrio SimpleRTK3b (Mosaic-H) GNSS receiver.</p> <p>:param antenna_pose: the pose of the main antenna in the robot's coordinate frame (yaw: direction to the auxiliary antenna)</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.GnssHardware._antenna_angle","title":"_antenna_angle  <code>instance-attribute</code>","text":"<pre><code>_antenna_angle = pi + atan2(y, x) - yaw\n</code></pre> <p>the angle from the robot's center to the main antenna</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.GnssHardware._antenna_distance","title":"_antenna_distance  <code>instance-attribute</code>","text":"<pre><code>_antenna_distance = sqrt(x ** 2 + y ** 2)\n</code></pre> <p>the distance from the robot's center to the main antenna</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.GnssHardware._convert_to_decimal","title":"_convert_to_decimal  <code>staticmethod</code>","text":"<pre><code>_convert_to_decimal(coord: str, direction: str) -&gt; float\n</code></pre> <p>Convert a coordinate in the format DDMM.mmmm to decimal degrees.</p> <p>:param coord: the coordinate to convert :param direction: the direction (N/S/E/W) :return: the coordinate in decimal degrees</p>"},{"location":"reference/rosys/hardware/#events_7","title":"Events","text":"Name Description NEW_MEASUREMENT a new measurement has been received (argument: <code>GnssMeasurement</code>)"},{"location":"reference/rosys/hardware/#rosys.hardware.GnssSimulation","title":"GnssSimulation","text":"<pre><code>GnssSimulation(\n    *,\n    wheels: WheelsSimulation,\n    lat_std_dev: float = 0.01,\n    lon_std_dev: float = 0.01,\n    heading_std_dev: float = 0.01,\n    gps_quality: GpsQuality = GpsQuality.RTK_FIXED\n)\n</code></pre> <p>               Bases: <code>Gnss</code></p> <p>Simulation of a GNSS receiver.</p> <p>:param wheels: the wheels to use for the simulation :param lat_std_dev: the standard deviation of the latitude in meters :param lon_std_dev: the standard deviation of the longitude in meters :param heading_std_dev: the standard deviation of the heading in degrees :param gps_quality: the quality of the GPS signal</p>"},{"location":"reference/rosys/hardware/#events_8","title":"Events","text":"Name Description NEW_MEASUREMENT a new measurement has been received (argument: <code>GnssMeasurement</code>)"},{"location":"reference/rosys/hardware/#rosys.hardware.Robot","title":"Robot","text":"<pre><code>Robot(modules: list[Module])\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>A robot that consists of a number of modules.</p> <p>It can be either a hardware robot or a simulation.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.RobotBrain","title":"RobotBrain","text":"<pre><code>RobotBrain(\n    communication: Communication,\n    *,\n    enable_esp_on_startup: bool = True\n)\n</code></pre> <p>This module manages the communication with a Zauberzeug Robot Brain.</p> <p>It expects a communication object, which is used for the actual read and write operations. Besides providing some basic methods like configuring or restarting the microcontroller, it augments and verifies checksums for each message.</p> <p>It also keeps track of the clock offset between the microcontroller and the host system, which is used to synchronize the hardware time with the system time. The clock offset is calculated by comparing the hardware time with the system time and averaging the differences over a number of samples. If the offset changes significantly, a notification is sent and the offset history is cleared.</p>"},{"location":"reference/rosys/hardware/#events_9","title":"Events","text":"Name Description LINE_RECEIVED a line has been received from the microcontroller (argument: line as string) FLASH_P0_COMPLETE flashing p0 was successful and 'Replica complete' was received"},{"location":"reference/rosys/hardware/#rosys.hardware.RobotHardware","title":"RobotHardware","text":"<pre><code>RobotHardware(\n    modules: list[Module], robot_brain: RobotBrain\n)\n</code></pre> <p>               Bases: <code>Robot</code></p> <p>A robot that consists of hardware modules.</p> <p>It generates Lizard code, forwards output to the hardware modules and sends commands to the robot brain.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.RobotSimulation","title":"RobotSimulation","text":"<pre><code>RobotSimulation(modules: list[Module])\n</code></pre> <p>               Bases: <code>Robot</code></p> <p>A robot that consists of simulated modules.</p> <p>It regularly calls the step method of all modules to allow them to update their internal state.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.SerialCommunication","title":"SerialCommunication","text":"<pre><code>SerialCommunication(\n    *,\n    device_path: str | None = None,\n    baud_rate: int = 115200\n)\n</code></pre> <p>               Bases: <code>Communication</code></p> <p>This module implements a communication via a serial device with a given baud rate.</p> <p>It contains a list of search paths for finding the serial device.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.SerialHardware","title":"SerialHardware","text":"<pre><code>SerialHardware(\n    robot_brain: RobotBrain,\n    *,\n    name: str = \"serial\",\n    rx_pin: int = 26,\n    tx_pin: int = 27,\n    baud: int = 115200,\n    num: int = 1\n)\n</code></pre> <p>               Bases: <code>ModuleHardware</code></p> <p>The serial module represents a serial connection with another device.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WebCommunication","title":"WebCommunication","text":"<pre><code>WebCommunication()\n</code></pre> <p>               Bases: <code>Communication</code></p> <p>Remote connection to the Robot Brain's ESP.</p> <p>This makes it possible to keep developing on your fast computer while communicating with the hardware components connected to a physical Robot Brain.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.Wheels","title":"Wheels","text":"<pre><code>Wheels(**kwargs)\n</code></pre> <p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>This module represents wheels for a two-wheel differential drive.</p> <p>Wheels can be moved using the <code>drive</code> methods and provide measured velocities as an event.</p>"},{"location":"reference/rosys/hardware/#events_10","title":"Events","text":"Name Description VELOCITY_MEASURED new velocity measurements are available for processing (argument: list of velocities)"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsHardware","title":"WheelsHardware","text":"<pre><code>WheelsHardware(\n    robot_brain: RobotBrain,\n    *,\n    can: CanHardware,\n    name: str = \"wheels\",\n    left_can_address: int = 0,\n    right_can_address: int = 256,\n    m_per_tick: float = 0.01,\n    width: float = 0.5,\n    is_left_reversed: bool = False,\n    is_right_reversed: bool = False\n)\n</code></pre> <p>               Bases: <code>Wheels</code>, <code>ModuleHardware</code></p> <p>This module implements wheels hardware.</p> <p>Drive and stop commands are forwarded to a given Robot Brain. Velocities are read and emitted regularly.</p>"},{"location":"reference/rosys/hardware/#events_11","title":"Events","text":"Name Description VELOCITY_MEASURED new velocity measurements are available for processing (argument: list of velocities)"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation","title":"WheelsSimulation","text":"<pre><code>WheelsSimulation(width: float = 0.5)\n</code></pre> <p>               Bases: <code>Wheels</code>, <code>ModuleSimulation</code></p> <p>This module simulates two wheels.</p> <p>Drive and stop commands impact internal velocities (linear and angular). A simulated pose is regularly updated with these velocities, while the velocities are emitted as an event.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.angular_velocity","title":"angular_velocity  <code>instance-attribute</code>","text":"<pre><code>angular_velocity: float = 0\n</code></pre> <p>The current angular velocity of the robot.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.friction_factor","title":"friction_factor  <code>instance-attribute</code>","text":"<pre><code>friction_factor: float = 0.0\n</code></pre> <p>The factor of friction for the wheels (0 = no friction, 1 = full friction).</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.inertia_factor","title":"inertia_factor  <code>instance-attribute</code>","text":"<pre><code>inertia_factor: float = 0.0\n</code></pre> <p>The factor of inertia for the wheels (0 = no inertia, 1 = full inertia).</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.is_blocking","title":"is_blocking  <code>instance-attribute</code>","text":"<pre><code>is_blocking: bool = False\n</code></pre> <p>If True, the wheels are blocking and the robot will not move.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.linear_velocity","title":"linear_velocity  <code>instance-attribute</code>","text":"<pre><code>linear_velocity: float = 0\n</code></pre> <p>The current linear velocity of the robot.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.pose","title":"pose  <code>instance-attribute</code>","text":"<pre><code>pose: Pose = Pose(time=time())\n</code></pre> <p>Provides the actual pose of the robot which can alter due to slippage.</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.slip_factor_left","title":"slip_factor_left  <code>instance-attribute</code>","text":"<pre><code>slip_factor_left: float = 0\n</code></pre> <p>The factor of slippage for the left wheel (0 = no slippage, 1 = full slippage).</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.slip_factor_right","title":"slip_factor_right  <code>instance-attribute</code>","text":"<pre><code>slip_factor_right: float = 0\n</code></pre> <p>The factor of slippage for the right wheel (0 = no slippage, 1 = full slippage).</p>"},{"location":"reference/rosys/hardware/#rosys.hardware.WheelsSimulation.width","title":"width  <code>instance-attribute</code>","text":"<pre><code>width: float = width\n</code></pre> <p>The distance between the wheels -- used to calculate actual drift when slip_factor_* is used.</p>"},{"location":"reference/rosys/hardware/#events_12","title":"Events","text":"Name Description VELOCITY_MEASURED new velocity measurements are available for processing (argument: list of velocities)"},{"location":"reference/rosys/helpers/","title":"helpers","text":""},{"location":"reference/rosys/helpers/#rosys.helpers.ramp","title":"ramp","text":"<pre><code>ramp(\n    x: float,\n    in1: float,\n    in2: float,\n    out1: float,\n    out2: float,\n    clip: bool = False,\n) -&gt; float\n</code></pre> <p>Map a value x from one range (in1, in2) to another (out1, out2).</p>"},{"location":"reference/rosys/helpers/#rosys.helpers.remove_indentation","title":"remove_indentation","text":"<pre><code>remove_indentation(text: str) -&gt; str\n</code></pre> <p>Remove indentation from a multi-line string based on the indentation of the first line.</p>"},{"location":"reference/rosys/pathplanning/","title":"pathplanning","text":""},{"location":"reference/rosys/pathplanning/#rosys.pathplanning.PathPlanner","title":"PathPlanner","text":"<pre><code>PathPlanner(robot_shape: Prism)\n</code></pre> <p>               Bases: <code>PersistentModule</code></p> <p>This module runs a path planning algorithm in a separate process.</p> <p>If given, the algorithm respects the given robot shape as well as a dictionary of accessible areas and a dictionary of obstacles, both of which a backed up and restored automatically. The path planner can search paths, check if a spline interferes with obstacles and get the distance of a pose to any obstacle.</p>"},{"location":"reference/rosys/pathplanning/#events","title":"Events","text":"Name Description OBSTACLES_CHANGED the obstacles have changed (argument: dictionary of obstacles) AREAS_CHANGED the areas have changed (argument: list of areas that have changed, can be None for all areas)"},{"location":"reference/rosys/system/","title":"system","text":""},{"location":"reference/rosys/system/#rosys.system.wifi_button","title":"wifi_button","text":"<pre><code>wifi_button()\n</code></pre> <p>               Bases: <code>button</code></p> <p>The WiFi button indicates the current connectivity state and allows setting a new WiFi connection.</p>"},{"location":"reference/rosys/vision/","title":"vision","text":""},{"location":"reference/rosys/vision/#rosys.vision.Autoupload","title":"Autoupload","text":"<p>               Bases: <code>Enum</code></p> <p>Configures the auto-submitting of images to the Learning Loop</p>"},{"location":"reference/rosys/vision/#rosys.vision.Autoupload.ALL","title":"ALL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ALL = 'all'\n</code></pre> <p>submit all images which are run through the detector</p>"},{"location":"reference/rosys/vision/#rosys.vision.Autoupload.DISABLED","title":"DISABLED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DISABLED = 'disabled'\n</code></pre> <p>no auto-submitting</p>"},{"location":"reference/rosys/vision/#rosys.vision.Autoupload.FILTERED","title":"FILTERED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FILTERED = 'filtered'\n</code></pre> <p>only submit images with novel detections and in an uncertainty range (this is the default)</p>"},{"location":"reference/rosys/vision/#events","title":"Events","text":"Name Description NEW_DETECTIONS detection on an image is completed (argument: image)"},{"location":"reference/rosys/vision/#rosys.vision.CameraProjector","title":"CameraProjector","text":"<pre><code>CameraProjector(\n    camera_provider: CalibratableCameraProvider,\n    *,\n    interval: float = 1.0\n)\n</code></pre> <p>The camera projector computes a grid of projected image points on the ground plane.</p> <p>It is mainly used for visualization purposes.</p>"},{"location":"reference/rosys/vision/#rosys.vision.CameraProvider","title":"CameraProvider","text":"<pre><code>CameraProvider(*, persistence_key: str | None = None)\n</code></pre> <p>               Bases: <code>Generic[T]</code>, <code>PersistentModule</code></p> <p>A camera provider holds a dictionary of cameras and manages additions and removals.</p> <p>The camera dictionary should not be modified directly but by using the camera provider's methods. This way respective events are emitted and consistency can be taken care of.</p> <p>The camera provider also creates an HTTP route to access camera images.</p>"},{"location":"reference/rosys/vision/#events_1","title":"Events","text":"Name Description CAMERA_ADDED a new camera has been added (argument: camera) CAMERA_REMOVED a camera has been removed (argument: camera id) NEW_IMAGE a new image is available (argument: image)"},{"location":"reference/rosys/vision/#rosys.vision.ConfigurableCamera","title":"ConfigurableCamera","text":"<pre><code>ConfigurableCamera(**kwargs)\n</code></pre> <p>               Bases: <code>Camera</code></p> <p>A generalized interface for adjusting camera parameters like exposure, brightness or fps.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector","title":"Detector","text":"<pre><code>Detector(*, name: str | None = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>A detector allows detecting objects in images.</p> <p>It also holds an upload queue for sending images with uncertain results to an active learning infrastructure like the Zauberzeug Learning Loop.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector.detect","title":"detect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>detect(\n    image: Image,\n    *,\n    autoupload: Autoupload = Autoupload.FILTERED,\n    tags: list[str] | None = None,\n    source: str | None = None,\n    creation_date: datetime | str | None = None\n) -&gt; Detections | None\n</code></pre> <p>Runs detections on the image and fills the <code>image.detections</code> property.</p> <p>The parameters <code>tags</code>, <code>source</code>, and <code>creation_date</code> are added as metadata if the image is uploaded.</p> <p>Note that the hardware detector uses a lazy strategy to schedule the inference tasks. In particular a queue with a maximum size of 1 is used. This means if the detector is busy, the image is not processed immediately, but queued up. If the <code>detect</code> function is called again, the queued image is dropped and the new image is queued instead. In this case this method returns <code>None</code>.</p> <p>:return: the detections found in the image. :raises DetectorException: if the detection fails.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector.fetch_detector_info","title":"fetch_detector_info  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>fetch_detector_info() -&gt; DetectorInfo\n</code></pre> <p>Retrieve information about the detector.</p> <p>:return: information about the detector. :raises DetectorException: if the about information cannot be retrieved.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector.fetch_model_version_info","title":"fetch_model_version_info  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>fetch_model_version_info() -&gt; ModelVersioningInfo\n</code></pre> <p>Retrieve information about the model version and versioning mode.</p> <p>:return: the information about the model versioning as data class. :raises DetectorException: if the detector is not connected or the information cannot be retrieved.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector.set_model_version","title":"set_model_version  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>set_model_version(\n    version: Literal[\"follow_loop\", \"pause\"] | str\n) -&gt; None\n</code></pre> <p>Set the model version or versioning mode.</p> <p>Set to \"follow_loop\" to automatically update the model version to the latest version in the learning loop. Set to \"pause\" to stop automatic updates and keep the current model version. Set to a version number (e.g. \"1.2\") to use a specific version.</p> <p>:raises DetectorException: if the version control mode is not valid or the version could not be set.</p>"},{"location":"reference/rosys/vision/#rosys.vision.Detector.upload","title":"upload  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>upload(\n    image: Image,\n    *,\n    tags: list[str] | None = None,\n    source: str | None = None,\n    creation_date: datetime | str | None = None\n) -&gt; None\n</code></pre> <p>Uploads the image to the Learning Loop.</p> <p>The parameters <code>tags</code>, <code>source</code>, and <code>creation_date</code> are added as metadata. If the image has detections, they are also uploaded.</p> <p>:raises DetectorException: if the upload fails.</p>"},{"location":"reference/rosys/vision/#events_2","title":"Events","text":"Name Description NEW_DETECTIONS detection on an image is completed (argument: image)"},{"location":"reference/rosys/vision/#rosys.vision.DetectorHardware","title":"DetectorHardware","text":"<pre><code>DetectorHardware(\n    *,\n    port: int = 8004,\n    name: str | None = None,\n    auto_disconnect: bool = True\n)\n</code></pre> <p>               Bases: <code>Detector</code></p> <p>This detector communicates with a YOLO detector via Socket.IO.</p> <p>It automatically connects and reconnects, submits and receives detections and sends images that should be uploaded to the Zauberzeug Learning Loop.</p> <p>Note: Images must be smaller than <code>MAX_IMAGE_SIZE</code> bytes (default: 10 MB).</p>"},{"location":"reference/rosys/vision/#rosys.vision.DetectorHardware.soft_reload","title":"soft_reload  <code>async</code>","text":"<pre><code>soft_reload() -&gt; None\n</code></pre> <p>Trigger a soft reload of the detector.</p> <p>:raises DetectorException: if the communication fails.</p>"},{"location":"reference/rosys/vision/#rosys.vision.DetectorSimulation","title":"DetectorSimulation","text":"<pre><code>DetectorSimulation(\n    camera_provider: CalibratableCameraProvider,\n    *,\n    noise: float = 1.0,\n    detection_delay: float = 0.4,\n    name: str | None = None\n)\n</code></pre> <p>               Bases: <code>Detector</code></p> <p>This detector simulates object detection.</p> <p>It requires a camera provider in order to check visibility using the cameras' calibrations. Individual camera IDs can be added to a set of <code>blocked_cameras</code> to simulate occlusions during pytests. A list of <code>simulated_objects</code> can be filled to define what can be detected. An optional <code>noise</code> parameter controls the spatial accuracy in pixels. An optional <code>detection_delay</code> parameter simulates the time it takes to process an image.</p>"},{"location":"reference/rosys/vision/#rosys.vision.MultiCameraProvider","title":"MultiCameraProvider","text":"<pre><code>MultiCameraProvider(*camera_providers: CameraProvider)\n</code></pre> <p>               Bases: <code>CameraProvider</code></p> <p>A multi-camera provider combines multiple camera providers into one.</p> <p>This is useful if another module requires a single camera provider but the robot has multiple camera sources like USB and WiFi cameras.</p>"},{"location":"reference/rosys/vision/#rosys.vision.RtspCameraProvider","title":"RtspCameraProvider","text":"<pre><code>RtspCameraProvider(\n    *,\n    frame_rate: int = 6,\n    jovision_profile: int = 0,\n    network_interface: str | None = None,\n    auto_scan: bool = True\n)\n</code></pre> <p>               Bases: <code>CameraProvider[RtspCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and provides real RTSP streaming cameras.</p>"},{"location":"reference/rosys/vision/#rosys.vision.SimulatedCameraProvider","title":"SimulatedCameraProvider","text":"<pre><code>SimulatedCameraProvider(\n    *,\n    simulate_failing: bool = False,\n    auto_scan: bool = True\n)\n</code></pre> <p>               Bases: <code>CameraProvider[SimulatedCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and simulates cameras and generates synthetic images.</p> <p>In the current implementation the images only contain the camera ID and the current time.</p>"},{"location":"reference/rosys/vision/#rosys.vision.SimulatedCameraProvider.scan_for_cameras","title":"scan_for_cameras  <code>async</code>","text":"<pre><code>scan_for_cameras() -&gt; AsyncGenerator[str, Any]\n</code></pre> <p>Simulated device discovery by returning all camera's IDs.</p> <p>If simulate_device_failure is set, disconnected cameras are returned with a fixed probability.</p>"},{"location":"reference/rosys/vision/#rosys.vision.UsbCameraProvider","title":"UsbCameraProvider","text":"<pre><code>UsbCameraProvider(*, auto_scan: bool = True)\n</code></pre> <p>               Bases: <code>CameraProvider[UsbCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and provides real USB cameras.</p> <p>Camera devices are discovered through video4linux (v4l) and accessed with openCV. Therefore the program v4l2ctl and openCV (including python bindings) must be available.</p>"},{"location":"reference/rosys/vision/#rosys.vision.camera_objects","title":"camera_objects","text":"<pre><code>camera_objects(\n    camera_provider: CalibratableCameraProvider,\n    camera_projector: CameraProjector,\n    *,\n    px_per_m: float = 10000,\n    debug: bool = False,\n    interval: float = 1.0\n)\n</code></pre> <p>               Bases: <code>Group</code></p> <p>This module provides a UI element for displaying cameras in a 3D scene.</p> <p>It requires a camera provider as a source of cameras as well as a camera projector to show the current images projected on the ground plane. The <code>px_per_m</code> argument can be used to scale the camera frustums. With <code>debug=True</code> camera IDs are shown (default: <code>False</code>).</p>"},{"location":"reference/rosys/vision/camera/","title":"camera","text":""},{"location":"reference/rosys/vision/camera/#rosys.vision.camera.ConfigurableCamera","title":"ConfigurableCamera","text":"<pre><code>ConfigurableCamera(**kwargs)\n</code></pre> <p>               Bases: <code>Camera</code></p> <p>A generalized interface for adjusting camera parameters like exposure, brightness or fps.</p>"},{"location":"reference/rosys/vision/rtsp_camera/","title":"rtsp_camera","text":""},{"location":"reference/rosys/vision/rtsp_camera/#rosys.vision.rtsp_camera.RtspCameraProvider","title":"RtspCameraProvider","text":"<pre><code>RtspCameraProvider(\n    *,\n    frame_rate: int = 6,\n    jovision_profile: int = 0,\n    network_interface: str | None = None,\n    auto_scan: bool = True\n)\n</code></pre> <p>               Bases: <code>CameraProvider[RtspCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and provides real RTSP streaming cameras.</p>"},{"location":"reference/rosys/vision/simulated_camera/","title":"simulated_camera","text":""},{"location":"reference/rosys/vision/simulated_camera/#rosys.vision.simulated_camera.SimulatedCameraProvider","title":"SimulatedCameraProvider","text":"<pre><code>SimulatedCameraProvider(\n    *,\n    simulate_failing: bool = False,\n    auto_scan: bool = True\n)\n</code></pre> <p>               Bases: <code>CameraProvider[SimulatedCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and simulates cameras and generates synthetic images.</p> <p>In the current implementation the images only contain the camera ID and the current time.</p>"},{"location":"reference/rosys/vision/simulated_camera/#rosys.vision.simulated_camera.SimulatedCameraProvider.scan_for_cameras","title":"scan_for_cameras  <code>async</code>","text":"<pre><code>scan_for_cameras() -&gt; AsyncGenerator[str, Any]\n</code></pre> <p>Simulated device discovery by returning all camera's IDs.</p> <p>If simulate_device_failure is set, disconnected cameras are returned with a fixed probability.</p>"},{"location":"reference/rosys/vision/usb_camera/","title":"usb_camera","text":""},{"location":"reference/rosys/vision/usb_camera/#rosys.vision.usb_camera.UsbCameraProvider","title":"UsbCameraProvider","text":"<pre><code>UsbCameraProvider(*, auto_scan: bool = True)\n</code></pre> <p>               Bases: <code>CameraProvider[UsbCamera]</code>, <code>PersistentModule</code></p> <p>This module collects and provides real USB cameras.</p> <p>Camera devices are discovered through video4linux (v4l) and accessed with openCV. Therefore the program v4l2ctl and openCV (including python bindings) must be available.</p>"}]}